stages:
  - update
  - build
  - test
  - bench

variables:
  PIPELINE_NAME:
    description: "Optional name to better identify this pipeline"
    value: ""
  CPU_CORES:
    description: "Select number of CPU cores and test workers"
    value: "8"
  PARALLEL_JOBS:
    description: "Number of parallel Slurm array jobs per CI job"
    value: "8"
  SLURM_TIMEOUT:
    description: "Timeout"
    value: "0-12" # [days-hours]
  MANUAL_CFG_PATH:
    description: "Use this config file instead of configs stored in the repo. Path must be accessible to runner"
    value: ""
  SLURM_QOS:
    description: "Optional QoS option (include --qos, e.g., --qos express)"
    value: ""

workflow:
  name: '$PIPELINE_NAME'

FINN Manual Benchmark:
  stage: bench
  rules:
    - if: $MANUAL_CFG_PATH != ""
  trigger:
    include: benchmarking/bench-ci.yml
  variables:
    - BENCH_CFG: "MANUAL"

FINN Benchmark Suite:
  stage: bench
  rules:
    - if: $MANUAL_CFG_PATH == ""
  trigger:
    include: benchmarking/bench-ci.yml
  parallel:
    matrix:
      - BENCH_CFG: [mvau_test, transformer_test, transformer_sweep, transformer_radioml_all]

#TODO: more control via (optional) variables
#TODO: move power measurement from polling-based script to its own job/runner
#TODO: ensure a freshly initialized workdir on job/runner level (e.g. created directories seem to stay there)
#TODO: (optionally) save ALL build artifacts/logs/temporary files to artifacts or PFS for debugging (maybe via Jacamar feature of setting individual persistent workdirs?)
#TODO: save stdout log separately as job artifact due to 4 MB limit (relevant for full test suite runs)
#TODO: fix clock frequency discrepancies between setting, synth, and driver
#TODO: run fetch-repos here and cache it between jobs due to GitHub server issues